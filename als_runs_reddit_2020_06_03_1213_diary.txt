Starting diary with name artifact_als_runs_reddit_2020_06_03_1213_diary.txt
Repository directory: /home/bwlarse/tensor_toolbox_sparse
  Local Branch: master
  Remote: origin (https://gitlab.com/bwlarsen/tensor_toolbox)
  Remote Branch: master
  Short Hash: [33mc8
  Up-to-Date: true
Repository directory: /home/bwlarse/cparls_sparse_experiments
  Local Branch: master
  Remote: origin (https://gitlab.com/bwlarsen/cparls_sparse_experiments)
  Remote Branch: master
  Short Hash: [33me8
  Up-to-Date: false
  Statuses...
     [31mM[m als_runs_amazon.m
     [31mM[m als_runs_uber.m
     [31mM[m arls_runs_amazon.m
     [31mM[m arls_runs_enron.m
     [31mM[m arls_runs_reddit.m
     [31mM[m epsilon_runs_enron.m
     [31mM[m epsilon_runs_reddit.m
     [31mM[m fest_test_enron.m
     [31mM[m fest_test_reddit.m
    [31m??[m cp_runs_reddit.m
  ==== Diffs ====
  [1mindex f88e0d7..e6d11fe 100644[m
  [1m--- a/als_runs_amazon.m[m
  [1m+++ b/als_runs_amazon.m[m
  [36m@@ -18,8 +18,8 @@[m [mif do_gitchecks[m
       gitstatus(pwd);[m
   end[m
   [m
  [31m-%% Load in Log Count Reddit Tensor[m
  [31m-nruns = 1;[m
  [32m+[m[32m%% Load in Amazon Tensor[m
  [32m+[m[32mnruns = 5;[m
   R = 25;[m
   fprintf('\n---Loading in Amazon Tensor---\n')[m
   tic;[m
  [36m@@ -29,8 +29,8 @@[m [mtoc[m
   X = amazon;[m
   clear amazon;[m
   [m
  [31m-sz = size(reddit);[m
  [31m-N = ndims(reddit);[m
  [32m+[m[32msz = size(X);[m
  [32m+[m[32mN = ndims(X);[m
   [m
   %% Set up  output[m
   output = struct;[m
  [36m@@ -68,7 +68,7 @@[m [mfor rep = 1:nruns[m
       [m
       % Save out the model after each run[m
       % sprintf[m
  [31m-    save('-v7.3', sprintf('%s-model%02i', aname, rep), 'M', 'info')    [m
  [32m+[m[32m    save('-v7.3', sprintf('%s-model%02i', aname, rep), 'info')[m[41m    [m
   end[m
   [m
   % Save out the traces and fits for all runs[m
  [1mdiff --git a/als_runs_uber.m b/als_runs_uber.m[m
  [1mindex acba17e..c961ff9 100644[m
  [1m--- a/als_runs_uber.m[m
  [1m+++ b/als_runs_uber.m[m
  [36m@@ -32,7 +32,7 @@[m [msz = size(uber);[m
   N = ndims(uber);[m
   [m
   %% Set up  output[m
  [31m-results = cell(nruns,ns,2);[m
  [32m+[m[32mresults = cell(nruns);[m
   [m
   rng('shuffle')[m
   [m
  [1mdiff --git a/arls_runs_amazon.m b/arls_runs_amazon.m[m
  [1mindex 9d39976..aa853bf 100644[m
  [1m--- a/arls_runs_amazon.m[m
  [1m+++ b/arls_runs_amazon.m[m
  [36m@@ -21,9 +21,9 @@[m [mend[m
   %% User setup for script [m
   nruns = 5;[m
   R = 25;[m
  [31m-srng = 2.^(16:17);[m
  [32m+[m[32msrng = 2.^(14:17);[m
   truefit = false;[m
  [31m-fsamp = 2^24; [m
  [32m+[m[32mfsamp = 2^27;[m[41m [m
   [m
   [m
   %% Load in Enron Tensor[m
  [1mdiff --git a/arls_runs_enron.m b/arls_runs_enron.m[m
  [1mindex a130673..450911d 100644[m
  [1m--- a/arls_runs_enron.m[m
  [1m+++ b/arls_runs_enron.m[m
  [36m@@ -19,11 +19,11 @@[m [mif do_gitchecks[m
   end[m
   [m
   %% User setup for script [m
  [31m-nruns = 2;[m
  [32m+[m[32mnruns = 5;[m
   R = 25;[m
  [31m-srng = 2.^(19);[m
  [32m+[m[32msrng = 2.^(18:19);[m
   truefit = false;[m
  [31m-fsamp = 2^23; [m
  [32m+[m[32mfsamp = 2^25;[m[41m [m
   [m
   [m
   %% Load in Enron Tensor[m
  [1mdiff --git a/arls_runs_reddit.m b/arls_runs_reddit.m[m
  [1mindex a433a2f..b8df5ca 100644[m
  [1m--- a/arls_runs_reddit.m[m
  [1m+++ b/arls_runs_reddit.m[m
  [36m@@ -19,11 +19,11 @@[m [mif do_gitchecks[m
   end[m
   [m
   %% User setup for script [m
  [31m-nruns = 5;[m
  [32m+[m[32mnruns = 3;[m
   R = 25;[m
   srng = 2.^(17);[m
   truefit = false;[m
  [31m-fsamp = 2^26; [m
  [32m+[m[32mfsamp = 2^28;[m[41m [m
   [m
   [m
   %% Load in Enron Tensor[m
  [36m@@ -41,7 +41,7 @@[m [mresults = cell(nruns,ns,2);[m
   [m
   %% Set up estimated f[m
   fprintf('---Setting up function estimators based on X---\n');[m
  [31m-rnginit('41ea123768800000');[m
  [32m+[m[32mrnginit;[m
   [m
   xnzidx = tt_sub2ind64(sz,X.subs);[m
   xnzidx = sort(xnzidx);[m
  [36m@@ -66,16 +66,16 @@[m [mfor rep = 1:nruns[m
           fprintf('\n---Starting run %i/%i with %i samples---\n', rep, nruns, s)[m
           sharedparams = {'init', Uinit, 'truefit', truefit, 'finalfit', true, 'nsamplsq', s, 'fsampler', fsampler};[m
   [m
  [31m-        %fprintf('\nFinding CP decomposition (Deterministic Inclusion): \n')[m
  [31m-        %rnginit;[m
  [31m-        %tic[m
  [31m-        %[M, ~, info] = cp_arls_leverage(X,R,'thresh', 1.0/s,sharedparams{:});[m
  [31m-        %time = toc;[m
  [31m-        %fprintf('Total Time (secs): %.3f\n', time)[m
  [32m+[m[32m        fprintf('\nFinding CP decomposition (Deterministic Inclusion): \n')[m
  [32m+[m[32m        rnginit;[m
  [32m+[m[32m        tic[m
  [32m+[m[32m        [M, ~, info] = cp_arls_leverage(X,R,'thresh', 1.0/s,sharedparams{:});[m
  [32m+[m[32m        time = toc;[m
  [32m+[m[32m        fprintf('Total Time (secs): %.3f\n', time)[m
           [m
  [31m-        %info.params.fsampler = 'removed';[m
  [31m-        %info.params.init = 'removed';[m
  [31m-        %results{rep,sidx,1} = info;[m
  [32m+[m[32m        info.params.fsampler = 'removed';[m
  [32m+[m[32m        info.params.init = 'removed';[m
  [32m+[m[32m        results{rep,sidx,1} = info;[m
   [m
           fprintf('\nFinding CP decomposition (No Deterministic): \n')[m
           rnginit;[m
  [1mdiff --git a/epsilon_runs_enron.m b/epsilon_runs_enron.m[m
  [1mindex cfa64c9..c9ff669 100644[m
  [1m--- a/epsilon_runs_enron.m[m
  [1m+++ b/epsilon_runs_enron.m[m
  [36m@@ -34,7 +34,7 @@[m [mfprintf('\tLoaded solution with R=%d\n', R);[m
   %% Test at final solution[m
   [m
   krng = [1 2 4];[m
  [31m-srng = [1e2 5e2 1e3 5e3 1e4 2.5e4 5e4 1e5 1.5e5 2.0e5];[m
  [32m+[m[32msrng = 2.^(7:18);[m
   crng = {@(s) []};[m
   trng = {@(s) [], @(s) 1/s};[m
   ntrials = 10; % Just for demo, use 10 for regular trials[m
  [36m@@ -50,4 +50,4 @@[m [mrnginit;[m
   [results_rand,info_rand] = epsilon_runs(X,R,krng,srng,crng,trng,ntrials);[m
   [m
   %%[m
  [31m-save('-v7.3', aname,'results','info', 'results_rand', 'info_rand');[m
  \ No newline at end of file[m
  [32m+[m[32msave('-v7.3', aname,'results','info', 'results_rand', 'info_rand');[m
  [1mdiff --git a/epsilon_runs_reddit.m b/epsilon_runs_reddit.m[m
  [1mindex 530e3a8..49eb7b8 100644[m
  [1m--- a/epsilon_runs_reddit.m[m
  [1m+++ b/epsilon_runs_reddit.m[m
  [36m@@ -33,11 +33,11 @@[m [mfprintf('\tLoaded solution with R=%d\n', R);[m
   [m
   %% Test at final solution[m
   [m
  [31m-krng = [1 2 3];[m
  [32m+[m[32mkrng = [1];[m
   srng = [2^17];[m
   crng = {@(s) []};[m
   trng = {@(s) [], @(s) 1/s};[m
  [31m-ntrials = 5; % Just for demo, use 10 for regular trials[m
  [32m+[m[32mntrials = 3; % Just for demo, use 10 for regular trials[m
   [m
   fprintf('\t Starting runs with loaded solution');[m
   rnginit;[m
  [36m@@ -50,4 +50,4 @@[m [mrnginit;[m
   [results_rand,info_rand] = epsilon_runs_nofit(X,R,krng,srng,crng,trng,ntrials);[m
   [m
   %%[m
  [31m-save('-v7.3', aname,'results','info', 'results_rand', 'info_rand');[m
  \ No newline at end of file[m
  [32m+[m[32msave('-v7.3', aname,'results','info', 'results_rand', 'info_rand');[m
  [1mdiff --git a/fest_test_enron.m b/fest_test_enron.m[m
  [1mindex e58ff41..7ee9385 100644[m
  [1m--- a/fest_test_enron.m[m
  [1m+++ b/fest_test_enron.m[m
  [36m@@ -1,7 +1,7 @@[m
   %% Estimated Fit Test for Enron Tensor[m
   [m
  [31m-load ('/home/bwlarse/Tensors/tensor_data_enron_large/enron_emails');[m
  [31m-load('/home/bwlarse/Tensors/tensor_data_enron_large/enron_emails_solutions')[m
  [32m+[m[32mload ('/home/bwlarse/Tensors/tensor_data_enron_large/enron_emails_log');[m
  [32m+[m[32mload('/home/bwlarse/Tensors/tensor_data_enron_large/enron_emails_log_solution')[m
   fprintf('\n---Loading in Enron Tensor---\n')[m
   [m
   X = enron;[m
  [1mdiff --git a/fest_test_reddit.m b/fest_test_reddit.m[m
  [1mindex 224db62..4886084 100644[m
  [1m--- a/fest_test_reddit.m[m
  [1m+++ b/fest_test_reddit.m[m
  [36m@@ -4,7 +4,7 @@[m [mload ('/home/bwlarse/Tensors/tensor_data_reddit/reddit_log');[m
   load('/home/bwlarse/Tensors/tensor_data_reddit/reddit_log_solution')[m
   fprintf('\n---Loading in Reddit Tensor (with log counts)---\n')[m
   [m
  [31m-X = enron;[m
  [32m+[m[32mX = reddit;[m
   P = M;[m
   P_normal = normalize(P, 1);[m
   [m
  ==== End Diffs ====

---Loading in Log Count Reddit Tensor---
Elapsed time is 351.474657 seconds.

---Starting run 1/1---
Generating random initialization: 
Random Seed in Hex: 41e5433eb2c00000
Finding CP decomposition: 
Random Seed in Hex: 41aae92b70000000

CP_ALS (with trace):

Tensor size: 8211298 x 176962 x 8116559 (1.179407e+19 total entries)
Sparse tensor: 4687474081 (4e-08%) Nonzeros and 1.179407e+19 (100.00%) Zeros
Finding CP decomposition with R=25
Fit change tolerance: 1.000000e-04
Max iterations: 50

 Iter  1: f = 2.070443e-02 f-delta = 2.1e-02 time = 9502.3 seconds 
 Iter  2: f = 4.728659e-02 f-delta = 2.7e-02 time = 9487.9 seconds 
 Iter  3: f = 5.121054e-02 f-delta = 3.9e-03 time = 9654.0 seconds 
 Iter  4: f = 5.244612e-02 f-delta = 1.2e-03 time = 9698.6 seconds 
 Iter  5: f = 5.304597e-02 f-delta = 6.0e-04 time = 10031.2 seconds 
 Iter  6: f = 5.342075e-02 f-delta = 3.7e-04 time = 9532.3 seconds 
 Iter  7: f = 5.369811e-02 f-delta = 2.8e-04 time = 9528.3 seconds 
 Iter  8: f = 5.392945e-02 f-delta = 2.3e-04 time = 9394.2 seconds 
 Iter  9: f = 5.413917e-02 f-delta = 2.1e-04 time = 9612.7 seconds 
 Iter 10: f = 5.433760e-02 f-delta = 2.0e-04 time = 9456.1 seconds 
 Iter 11: f = 5.452821e-02 f-delta = 1.9e-04 time = 9534.6 seconds 
 Iter 12: f = 5.471231e-02 f-delta = 1.8e-04 time = 9640.5 seconds 
 Iter 13: f = 5.489111e-02 f-delta = 1.8e-04 time = 9619.0 seconds 
 Iter 14: f = 5.506613e-02 f-delta = 1.8e-04 time = 9694.9 seconds 
 Iter 15: f = 5.523905e-02 f-delta = 1.7e-04 time = 9776.9 seconds 
 Iter 16: f = 5.541136e-02 f-delta = 1.7e-04 time = 9672.9 seconds 
 Iter 17: f = 5.558443e-02 f-delta = 1.7e-04 time = 9498.4 seconds 
 Iter 18: f = 5.575943e-02 f-delta = 1.8e-04 time = 9732.5 seconds 
 Iter 19: f = 5.593727e-02 f-delta = 1.8e-04 time = 9810.7 seconds 
 Iter 20: f = 5.611819e-02 f-delta = 1.8e-04 time = 9715.9 seconds 
 Iter 21: f = 5.630165e-02 f-delta = 1.8e-04 time = 9990.9 seconds 
 Iter 22: f = 5.648655e-02 f-delta = 1.8e-04 time = 9529.2 seconds 
 Iter 23: f = 5.667209e-02 f-delta = 1.9e-04 time = 9613.2 seconds 
 Iter 24: f = 5.685844e-02 f-delta = 1.9e-04 time = 9648.3 seconds 
 Iter 25: f = 5.704672e-02 f-delta = 1.9e-04 time = 9643.6 seconds 
 Iter 26: f = 5.723794e-02 f-delta = 1.9e-04 time = 9536.4 seconds 
 Iter 27: f = 5.743209e-02 f-delta = 1.9e-04 time = 9312.3 seconds 
 Iter 28: f = 5.762772e-02 f-delta = 2.0e-04 time = 9270.7 seconds 
 Iter 29: f = 5.782234e-02 f-delta = 1.9e-04 time = 9509.3 seconds 
 Iter 30: f = 5.801280e-02 f-delta = 1.9e-04 time = 9309.9 seconds 
 Iter 31: f = 5.819552e-02 f-delta = 1.8e-04 time = 9276.4 seconds 
 Iter 32: f = 5.836665e-02 f-delta = 1.7e-04 time = 9341.3 seconds 
 Iter 33: f = 5.852257e-02 f-delta = 1.6e-04 time = 9451.6 seconds 
 Iter 34: f = 5.866066e-02 f-delta = 1.4e-04 time = 9570.8 seconds 
 Iter 35: f = 5.878006e-02 f-delta = 1.2e-04 time = 9630.2 seconds 
 Iter 36: f = 5.888194e-02 f-delta = 1.0e-04 time = 9448.5 seconds 
 Iter 37: f = 5.896912e-02 f-delta = 8.7e-05 time = 9409.8 seconds 
 Final f = 5.896912e-02 
Total Time (secs): 356978.887
